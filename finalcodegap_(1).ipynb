{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6a2c07b4-5d3e-4eb5-962b-90f2e16ffcc3",
      "metadata": {
        "id": "6a2c07b4-5d3e-4eb5-962b-90f2e16ffcc3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "\n",
        "class ServicePlacementEnv(gym.Env):\n",
        "    def __init__(self, utilities, vm_requirements, capacities):\n",
        "        super(ServicePlacementEnv, self).__init__()\n",
        "        self.utilities = np.array(utilities)\n",
        "        self.vm_requirements = np.array(vm_requirements)\n",
        "        self.capacities = np.array(capacities)\n",
        "\n",
        "        self.num_servers, self.num_users = self.utilities.shape\n",
        "\n",
        "        # Action space: one action per server\n",
        "        self.action_space = spaces.Discrete(self.num_servers)\n",
        "\n",
        "        # Observation space: variable servers, 2 features per server\n",
        "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(self.num_servers, 2), dtype=np.float32)\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.remaining_capacities = self.capacities.copy()\n",
        "        self.current_user = 0\n",
        "        self.server_assignments = np.zeros((self.num_users, self.num_servers))\n",
        "        return self._get_state()\n",
        "\n",
        "    def _get_state(self):\n",
        "        if self.current_user >= self.num_users:\n",
        "            current_requirements = np.zeros(self.num_servers)\n",
        "        else:\n",
        "            current_requirements = [self.vm_requirements[s][self.current_user] for s in range(self.num_servers)]\n",
        "\n",
        "        # Stack capacities and current requirements (shape: [num_servers, 2])\n",
        "        state = np.stack([self.remaining_capacities, current_requirements], axis=1).astype(np.float32)\n",
        "        return state\n",
        "\n",
        "    def get_valid_actions(self):\n",
        "        return [s for s in range(self.num_servers)\n",
        "                if self.remaining_capacities[s] >= self.vm_requirements[s][self.current_user]]\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.current_user >= self.num_users:\n",
        "            return self._get_state(), 0, True, {}\n",
        "\n",
        "        valid_actions = self.get_valid_actions()\n",
        "        reward = 0\n",
        "\n",
        "        if not valid_actions:\n",
        "            self.current_user += 1\n",
        "            done = self.current_user >= self.num_users\n",
        "            return self._get_state(), -5, done, {}\n",
        "\n",
        "        if action in valid_actions:\n",
        "            reward = self.utilities[action][self.current_user]\n",
        "            self.remaining_capacities[action] -= self.vm_requirements[action][self.current_user]\n",
        "            self.server_assignments[self.current_user, action] = 1\n",
        "        else:\n",
        "            reward = -10\n",
        "\n",
        "        self.current_user += 1\n",
        "        done = self.current_user >= self.num_users\n",
        "        return self._get_state(), reward, done, {}\n",
        "\n",
        "    def get_assignments(self):\n",
        "        return self.server_assignments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "98e56862-2dd4-4b6e-b957-1abc4da2fd48",
      "metadata": {
        "id": "98e56862-2dd4-4b6e-b957-1abc4da2fd48"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import deque\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, feature_dim, max_servers):\n",
        "        self.feature_dim = feature_dim        # Features per server (2: capacity, demand)\n",
        "        self.max_servers = max_servers        # Maximum servers across all problems\n",
        "        self.memory = deque(maxlen=5000)\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.model = self._build_model()\n",
        "\n",
        "    def _build_model(self):\n",
        "        inputs = layers.Input(shape=(None, self.feature_dim))  # Variable server count, fixed feature size\n",
        "        x = layers.Masking(mask_value=0.0)(inputs)\n",
        "        x = layers.LSTM(64)(x)\n",
        "        x = layers.Dense(64, activation='relu')(x)\n",
        "        outputs = layers.Dense(self.max_servers, activation='linear')(x)\n",
        "\n",
        "        model = models.Model(inputs, outputs)\n",
        "        model.compile(loss='mse', optimizer=optimizers.Adam(0.001))\n",
        "        return model\n",
        "\n",
        "    def act(self, state, valid_actions):\n",
        "        # Pad state to maximum server size for consistency\n",
        "        padded_state = self._pad_state(state)\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.choice(valid_actions)\n",
        "        q_values = self.model.predict(np.array([padded_state]), verbose=0)[0]\n",
        "        masked_q_values = [q_values[a] if a in valid_actions else -np.inf for a in range(state.shape[0])]\n",
        "        return np.argmax(masked_q_values)\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def replay(self, batch_size=32):\n",
        "        minibatch = random.sample(self.memory, min(len(self.memory), batch_size))\n",
        "\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            padded_state = self._pad_state(state)\n",
        "            padded_next_state = self._pad_state(next_state)\n",
        "\n",
        "            target = reward\n",
        "            if not done:\n",
        "                next_q_values = self.model.predict(np.array([padded_next_state]), verbose=0)[0]\n",
        "                target += self.gamma * np.max(next_q_values)\n",
        "\n",
        "            target_f = self.model.predict(np.array([padded_state]), verbose=0)\n",
        "            target_f[0][action] = target\n",
        "\n",
        "            self.model.fit(np.array([padded_state]), target_f, epochs=1, verbose=0)\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def _pad_state(self, state):\n",
        "        padded = np.zeros((self.max_servers, self.feature_dim))\n",
        "        padded[:state.shape[0], :] = state\n",
        "        return padded\n",
        "\n",
        "    def save(self, model_path):\n",
        "        self.model.save(model_path)\n",
        "\n",
        "    def load(self, model_path):\n",
        "        self.model = models.load_model(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0bfd8cb8-d538-492c-882b-27539f611343",
      "metadata": {
        "id": "0bfd8cb8-d538-492c-882b-27539f611343"
      },
      "outputs": [],
      "source": [
        "def parse_gap_file(filepath):\n",
        "    problems = []\n",
        "    with open(filepath, 'r') as file:\n",
        "        while True:\n",
        "            line = file.readline()\n",
        "            if not line:\n",
        "                break\n",
        "            m_n = line.strip().split()\n",
        "            if len(m_n) != 2:\n",
        "                continue\n",
        "            m, n = map(int, m_n)\n",
        "            utilities = [list(map(int, file.readline().strip().split())) for _ in range(m)]\n",
        "            vm_reqs = [list(map(int, file.readline().strip().split())) for _ in range(m)]\n",
        "            capacities = list(map(int, file.readline().strip().split()))\n",
        "            problems.append((utilities, vm_reqs, capacities))\n",
        "    return problems\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a0ec373-b1b5-43e8-ad05-3941a4bb6b37",
      "metadata": {
        "id": "5a0ec373-b1b5-43e8-ad05-3941a4bb6b37",
        "outputId": "39f6f0ee-e7a0-4385-e343-4b66c6e4a7e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Training on Problem Set 1/44 ===\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m     state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m     45\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m---> 47\u001b[0m agent\u001b[38;5;241m.\u001b[39mreplay(batch_size)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Print training progress\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (e\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "Cell \u001b[1;32mIn[3], line 56\u001b[0m, in \u001b[0;36mDQNAgent.replay\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     53\u001b[0m     target_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39marray([padded_state]), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     54\u001b[0m     target_f[\u001b[38;5;241m0\u001b[39m][action] \u001b[38;5;241m=\u001b[39m target\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39marray([padded_state]), target_f, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon_min:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon_decay\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:369\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    367\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m--> 369\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m         callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m    371\u001b[0m         logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:734\u001b[0m, in \u001b[0;36mTFEpochIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_epoch_iterator)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:112\u001b[0m, in \u001b[0;36mEpochIterator._enumerate_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_seen \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches:\n\u001b[1;32m--> 112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iterator())\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:501\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops\u001b[38;5;241m.\u001b[39minside_function():\n\u001b[0;32m    500\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m iterator_ops\u001b[38;5;241m.\u001b[39mOwnedIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration in eager mode or within tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:709\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    705\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot be specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 709\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_iterator(dataset)\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_call_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:748\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    745\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[0;32m    746\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_output_types)\n\u001b[0;32m    747\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 748\u001b[0m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmake_iterator(ds_variant, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator_resource)\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3478\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3477\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3478\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[0;32m   3479\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMakeIterator\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, dataset, iterator)\n\u001b[0;32m   3480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3481\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "# === Load problems from file ===\n",
        "input_file = \"train.txt\"\n",
        "problems = parse_gap_file(input_file)\n",
        "\n",
        "# Determine the maximum number of servers across all problem sets\n",
        "max_servers = max(len(p[2]) for p in problems)  # capacities length = num_servers\n",
        "feature_dim = 2  # [remaining capacity, current demand]\n",
        "\n",
        "# Initialize agent with maximum servers and feature dimensions\n",
        "agent = DQNAgent(feature_dim=feature_dim, max_servers=max_servers)\n",
        "\n",
        "# Adjust epsilon settings for long training\n",
        "agent.epsilon = 1.0\n",
        "agent.epsilon_min = 0.05     # Allow minimum 5% random exploration\n",
        "agent.epsilon_decay = 0.999  # Very slow decay over episodes\n",
        "\n",
        "# Training parameters\n",
        "episodes = 100\n",
        "batch_size = 32\n",
        "\n",
        "# === Training ===\n",
        "for idx, (utilities, vm_reqs, capacities) in enumerate(problems):\n",
        "    print(f\"\\n=== Training on Problem Set {idx+1}/{len(problems)} ===\")\n",
        "\n",
        "    env = ServicePlacementEnv(utilities, vm_reqs, capacities)\n",
        "\n",
        "    for e in range(episodes):\n",
        "        state = env.reset()\n",
        "        total_reward = 0\n",
        "        done = False\n",
        "\n",
        "        while not done:\n",
        "            valid_actions = env.get_valid_actions()\n",
        "            if not valid_actions:\n",
        "                action = 0\n",
        "            else:\n",
        "                action = agent.act(state, valid_actions)\n",
        "\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            agent.remember(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "\n",
        "        agent.replay(batch_size)\n",
        "\n",
        "        # Print training progress\n",
        "        if (e+1) % 20 == 0:\n",
        "            print(f\"  Episode {e+1}/{episodes} | Total Reward: {total_reward:.2f} | Epsilon: {agent.epsilon:.4f}\")\n",
        "         # Print episode details\n",
        "        print(f\"Episode {e+1}/{episodes} | Total Reward: {total_reward:.2f} | Epsilon: {agent.epsilon:.4f}\")\n",
        "\n",
        "    # Optional: reset epsilon slightly after every few problem sets (refresh exploration)\n",
        "    if (idx + 1) % 10 == 0:\n",
        "        agent.epsilon = max(agent.epsilon, 0.2)\n",
        "        print(f\"--- Epsilon reset to {agent.epsilon:.4f} after {idx+1} problem sets ---\")\n",
        "\n",
        "# Save the final trained model\n",
        "agent.save(\"generalized_dqn_model.keras\")\n",
        "print(\"\\n Training completed and model saved as 'generalized_dqn_model.keras' \")\n",
        "# === Testing / Evaluation ===\n",
        "print(\"\\n=== Testing on all problem sets ===\")\n",
        "agent.epsilon = 0  # Disable exploration for evaluation\n",
        "\n",
        "for idx, (utilities, vm_reqs, capacities) in enumerate(problems):\n",
        "    env = ServicePlacementEnv(utilities, vm_reqs, capacities)\n",
        "    state = env.reset()\n",
        "    final_reward = 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        valid_actions = env.get_valid_actions()\n",
        "        action = agent.act(state, valid_actions) if valid_actions else 0\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        final_reward += reward\n",
        "\n",
        "    assignments = env.get_assignments()\n",
        "    users_assigned = np.sum(assignments.sum(axis=1) > 0)\n",
        "\n",
        "    print(f\"\\n--- Problem Set {idx+1} ---\")\n",
        "    print(f\"Users Assigned: {users_assigned} / {env.num_users}\")\n",
        "    print(f\"Final Reward: {final_reward}\")\n",
        "    print(\"Assignment Matrix (Users x Servers):\")\n",
        "    print(assignments.astype(int))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "965b0505-7350-4884-8048-c468a86af9d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "965b0505-7350-4884-8048-c468a86af9d1",
        "outputId": "1169de23-5cef-4b95-d843-c77b82c26a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Testing on Test Problems ===\n",
            "\n",
            "--- Test Problem 1 ---\n",
            "Users Assigned: 13 / 15\n",
            "Final Reward: 243.0\n",
            "Optimal Reward: 326\n",
            "Accuracy: 74.5398773006135\n",
            "Assignment Matrix (Users x Servers):\n",
            "[[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [1 0 0 0 0]]\n",
            "\n",
            "--- Test Problem 2 ---\n",
            "Users Assigned: 13 / 15\n",
            "Final Reward: 243.0\n",
            "Optimal Reward: 326\n",
            "Accuracy: 74.5398773006135\n",
            "Assignment Matrix (Users x Servers):\n",
            "[[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [1 0 0 0 0]]\n",
            "\n",
            "--- Test Problem 3 ---\n",
            "Users Assigned: 18 / 20\n",
            "Final Reward: 302.0\n",
            "Optimal Reward: 428\n",
            "Accuracy: 70.56074766355141\n",
            "Assignment Matrix (Users x Servers):\n",
            "[[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [1 0 0 0 0]]\n",
            "\n",
            "--- Test Problem 4 ---\n",
            "Users Assigned: 21 / 25\n",
            "Final Reward: 404.0\n",
            "Optimal Reward: 564\n",
            "Accuracy: 71.63120567375887\n",
            "Assignment Matrix (Users x Servers):\n",
            "[[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]]\n",
            "\n",
            "--- Test Problem 5 ---\n",
            "Users Assigned: 28 / 30\n",
            "Final Reward: 518.0\n",
            "Optimal Reward: 664\n",
            "Accuracy: 78.01204819277109\n",
            "Assignment Matrix (Users x Servers):\n",
            "[[0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]]\n",
            "\n",
            "--- Test Problem 6 ---\n",
            "Users Assigned: 21 / 24\n",
            "Final Reward: 403.0\n",
            "Optimal Reward: 559\n",
            "Accuracy: 72.09302325581396\n",
            "Assignment Matrix (Users x Servers):\n",
            "[[0 0 0 0 0 1 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [1 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0]]\n",
            "\n",
            "--- Test Problem 7 ---\n",
            "Users Assigned: 28 / 32\n",
            "Final Reward: 528.0\n",
            "Optimal Reward: 747\n",
            "Accuracy: 70.68273092369478\n",
            "Assignment Matrix (Users x Servers):\n",
            "[[0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [1 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "\n",
            "--- Test Problem 8 ---\n",
            "Users Assigned: 36 / 40\n",
            "Final Reward: 698.0\n",
            "Optimal Reward: 951\n",
            "Accuracy: 73.39642481598318\n",
            "Assignment Matrix (Users x Servers):\n",
            "[[0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [1 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "\n",
            "--- Test Problem 9 ---\n",
            "Users Assigned: 41 / 48\n",
            "Final Reward: 785.0\n",
            "Optimal Reward: 1127\n",
            "Accuracy: 69.65394853593611\n",
            "Assignment Matrix (Users x Servers):\n",
            "[[0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1]\n",
            " [1 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0]]\n",
            "\n",
            "--- Test Problem 10 ---\n",
            "Users Assigned: 27 / 30\n",
            "Final Reward: 527.0\n",
            "Optimal Reward: 706\n",
            "Accuracy: 74.6458923512748\n",
            "Assignment Matrix (Users x Servers):\n",
            "[[0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "\n",
            "--- Test Problem 11 ---\n",
            "Users Assigned: 34 / 40\n",
            "Final Reward: 643.0\n",
            "Optimal Reward: 947\n",
            "Accuracy: 67.89862724392819\n",
            "Assignment Matrix (Users x Servers):\n",
            "[[0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "\n",
            "--- Test Problem 12 ---\n",
            "Users Assigned: 50 / 50\n",
            "Final Reward: 826.0\n",
            "Optimal Reward: 1171\n",
            "Accuracy: 70.53800170794193\n",
            "Assignment Matrix (Users x Servers):\n",
            "[[0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1]\n",
            " [1 0 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the environment and DQNAgent classes\n",
        "# (Assume they are already defined above as you gave)\n",
        "\n",
        "# Function to parse test file (same as for train file)\n",
        "def parse_gap_file(file_path):\n",
        "    problems = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        if lines[i].strip() == '':\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        num_servers, num_users = map(int, lines[i].split())\n",
        "        i += 1\n",
        "\n",
        "        utilities = []\n",
        "        for _ in range(num_servers):\n",
        "            utilities.append(list(map(float, lines[i].split())))\n",
        "            i += 1\n",
        "\n",
        "        vm_requirements = []\n",
        "        for _ in range(num_servers):\n",
        "            vm_requirements.append(list(map(float, lines[i].split())))\n",
        "            i += 1\n",
        "\n",
        "        capacities = list(map(float, lines[i].split()))\n",
        "        i += 1\n",
        "\n",
        "        problems.append((np.array(utilities), np.array(vm_requirements), np.array(capacities)))\n",
        "\n",
        "    return problems\n",
        "\n",
        "# === Load the trained model ===\n",
        "feature_dim = 2  # [capacity, demand]\n",
        "\n",
        "# Load test problems\n",
        "test_file = \"test.txt\"\n",
        "test_problems = parse_gap_file(test_file)\n",
        "\n",
        "# Find maximum servers in test problems (should match training max_servers ideally)\n",
        "max_servers = max(len(p[2]) for p in test_problems)\n",
        "\n",
        "# Create a DQNAgent object (dummy) just to access act(), but load the trained model\n",
        "agent = DQNAgent(feature_dim=feature_dim, max_servers=max_servers)\n",
        "agent.load(\"generalized_dqn_model.keras\")\n",
        "agent.epsilon = 0  # No exploration during testing\n",
        "optimal_rewards = [326,326,428,564,664,559,747,951,1127,706,947,1171]\n",
        "#optimal_rewards = [942,949,968,945,951]\n",
        "# === Testing ===\n",
        "print(\"\\n=== Testing on Test Problems ===\")\n",
        "\n",
        "for idx, (utilities, vm_reqs, capacities) in enumerate(test_problems):\n",
        "    env = ServicePlacementEnv(utilities, vm_reqs, capacities)\n",
        "    state = env.reset()\n",
        "    final_reward = 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        valid_actions = env.get_valid_actions()\n",
        "        action = agent.act(state, valid_actions) if valid_actions else 0\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        final_reward += reward\n",
        "\n",
        "    assignments = env.get_assignments()\n",
        "    users_assigned = np.sum(assignments.sum(axis=1) > 0)\n",
        "\n",
        "    print(f\"\\n--- Test Problem {idx+1} ---\")\n",
        "    print(f\"Users Assigned: {users_assigned} / {env.num_users}\")\n",
        "    print(f\"Final Reward: {final_reward}\")\n",
        "    print(f\"Optimal Reward: {optimal_rewards[idx]}\")\n",
        "    print(f\"Accuracy: {100-(abs(final_reward-optimal_rewards[idx])/optimal_rewards[idx])*100}\")\n",
        "    print(\"Assignment Matrix (Users x Servers):\")\n",
        "    print(assignments.astype(int))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b4341b3-80de-407e-8a65-9301b9109f6e",
      "metadata": {
        "id": "3b4341b3-80de-407e-8a65-9301b9109f6e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}